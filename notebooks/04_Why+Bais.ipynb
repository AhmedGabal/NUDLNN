{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do and exploration of the IRIS data set to see is the bias term is significant..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "] activate ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using DelimitedFiles\n",
    "using Flux,  Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd(@__DIR__)\n",
    "\n",
    "isfile(\"iris.data\") ||\n",
    "  download(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\"iris.data\")\n",
    "\n",
    "data= readdlm(\"iris.data\",',');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes= data[:,end];\n",
    "features= data[:,1:4];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_classes=unique(classes)\n",
    "decoded_classes=[findfirst(x->x==c,u_classes) for c in classes];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = convert(Array{Float64, 2}, features');\n",
    "Y = onehotbatch(decoded_classes, 1:3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetitions: 500\n",
      "Loss = 0.6872719703507694 (tracked)\n",
      "Repetitions: 1000\n",
      "Loss = 0.422628938690908 (tracked)\n",
      "Repetitions: 1500\n",
      "Loss = 0.27181547171747245 (tracked)\n",
      "Repetitions: 2000\n",
      "Loss = 0.1898477374686207 (tracked)\n",
      "Repetitions: 2500\n",
      "Loss = 0.12760106784943112 (tracked)\n",
      "Repetitions: 3000\n",
      "Loss = 0.09598870641249985 (tracked)\n",
      "Repetitions: 3500\n",
      "Loss = 0.09018862994700202 (tracked)\n"
     ]
    }
   ],
   "source": [
    "for repetitions in 500 : 500 : 3500 \n",
    "    println(\"Repetitions: \", repetitions)\n",
    "    lossesWithoutBais = []\n",
    "    for i in 1: 30\n",
    "        W1= param(rand(5,4))\n",
    "        W2= param(rand(3,5))\n",
    "        W = Flux.Params([W1, W2])\n",
    "        \n",
    "        function modelWithoutBais(x)\n",
    "            layer1= W1 * x\n",
    "            layer2= W2 * layer1\n",
    "            softmax(layer2)\n",
    "        end\n",
    "        currentModel = modelWithoutBais\n",
    "        loss(x, y) = crossentropy(currentModel(x), y)\n",
    "\n",
    "        accuracy(x, y) = mean(onecold(currentModel(x)) .== onecold(y))\n",
    "\n",
    "        dataset = repeated((X, Y), repetitions)\n",
    "        opt = ADAM(W)\n",
    "\n",
    "        Flux.train!(loss, dataset, opt)\n",
    "        push!(lossesWithoutBais, loss(X, Y))\n",
    "    end\n",
    "    println(\"Loss = \", mean(lossesWithoutBais))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetitions: 500\n",
      "Loss = 0.6786520849579296 (tracked)\n",
      "Repetitions: 1000\n",
      "Loss = 0.41155734902170066 (tracked)\n",
      "Repetitions: 1500\n",
      "Loss = 0.2543700982866663 (tracked)\n",
      "Repetitions: 2000\n",
      "Loss = 0.17009766037887833 (tracked)\n",
      "Repetitions: 2500\n",
      "Loss = 0.12448394492268515 (tracked)\n",
      "Repetitions: 3000\n",
      "Loss = 0.08256327975300788 (tracked)\n",
      "Repetitions: 3500\n",
      "Loss = 0.07442579291225397 (tracked)\n"
     ]
    }
   ],
   "source": [
    "for repetitions in 500 : 500 : 3500 \n",
    "    println(\"Repetitions: \", repetitions)\n",
    "    lossesWithBais = []\n",
    "    for i in 1: 30\n",
    "        W1= param(rand(5,4))\n",
    "        W2= param(rand(3,5))\n",
    "\n",
    "        B1= param(rand(5))\n",
    "        B2= param(rand(3))\n",
    "\n",
    "        W = Flux.Params([W1, W2, B1, B2])\n",
    "        function modelWithBais(x)\n",
    "            layer1= W1 * x .+ B1\n",
    "            layer2= W2 * layer1 .+ B2\n",
    "            softmax(layer2)\n",
    "        end\n",
    "\n",
    "        currentModel = modelWithBais\n",
    "        loss(x, y) = crossentropy(currentModel(x), y)\n",
    "\n",
    "        accuracy(x, y) = mean(onecold(currentModel(x)) .== onecold(y))\n",
    "\n",
    "        dataset = repeated((X, Y), repetitions)\n",
    "        opt = ADAM(W)\n",
    "\n",
    "        Flux.train!(loss, dataset, opt)\n",
    "\n",
    "        push!(lossesWithBais, loss(X, Y))\n",
    "    end\n",
    "    println(\"Loss = \", mean(lossesWithBais))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.1",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
